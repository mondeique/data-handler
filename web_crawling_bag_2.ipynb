{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MYBAG web crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "모든 백 사진 url 다운로드를 시작합니다\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "1번째 페이지 이미지를 다운로드 중입니다!\n",
      "2번째 페이지 이미지를 다운로드 중입니다!\n",
      "3번째 페이지 이미지를 다운로드 중입니다!\n",
      "4번째 페이지 이미지를 다운로드 중입니다!\n",
      "5번째 페이지 이미지를 다운로드 중입니다!\n",
      "6번째 페이지 이미지를 다운로드 중입니다!\n",
      "7번째 페이지 이미지를 다운로드 중입니다!\n",
      "8번째 페이지 이미지를 다운로드 중입니다!\n",
      "9번째 페이지 이미지를 다운로드 중입니다!\n",
      "10번째 페이지 이미지를 다운로드 중입니다!\n",
      "11번째 페이지 이미지를 다운로드 중입니다!\n",
      "12번째 페이지 이미지를 다운로드 중입니다!\n",
      "13번째 페이지 이미지를 다운로드 중입니다!\n",
      "14번째 페이지 이미지를 다운로드 중입니다!\n",
      "15번째 페이지 이미지를 다운로드 중입니다!\n",
      "16번째 페이지 이미지를 다운로드 중입니다!\n",
      "17번째 페이지 이미지를 다운로드 중입니다!\n",
      "18번째 페이지 이미지를 다운로드 중입니다!\n",
      "19번째 페이지 이미지를 다운로드 중입니다!\n",
      "20번째 페이지 이미지를 다운로드 중입니다!\n",
      "21번째 페이지 이미지를 다운로드 중입니다!\n",
      "22번째 페이지 이미지를 다운로드 중입니다!\n",
      "23번째 페이지 이미지를 다운로드 중입니다!\n",
      "24번째 페이지 이미지를 다운로드 중입니다!\n"
     ]
    }
   ],
   "source": [
    "## All bag\n",
    "\n",
    "from bs4 import BeautifulSoup \n",
    "from urllib.request import urlopen \n",
    "import time\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"모든 백 사진 url 다운로드를 시작합니다\")\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "current_page = 1\n",
    "\n",
    "img_url_list = []\n",
    "\n",
    "while current_page <= 24:\n",
    "    print(str(current_page) + \"번째 페이지 이미지를 다운로드 중입니다!\")\n",
    "    url = 'https://www.mybag.com/women/bags.list?productsPerPage=66' + '&pageNumber=' + str(current_page)\n",
    "    web = urlopen(url)\n",
    "    source = BeautifulSoup(web, 'html.parser')\n",
    "    for a in source.find_all('div', {\"class\" : \"productBlock_imageContainer\" }):\n",
    "        for url in a.find_all(\"img\"):\n",
    "            if url[\"src\"].startswith('https://s'):\n",
    "                img_url_list.append(url[\"src\"])\n",
    "                \n",
    "    current_page = current_page + 1            \n",
    "    time.sleep(5)\n",
    "\n",
    "\n",
    "mybag_img_url_list = list(set(img_url_list))\n",
    "\n",
    "mybag_img_url_list\n",
    "\n",
    "mybag_img_url_list = list(set(mybag_img_url_list))\n",
    "\n",
    "len(mybag_img_url_list)\n",
    "\n",
    "## write to csv file\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "with open('./data/bag_image_url_csv/mybag_all_bag.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f, quoting=csv.QUOTE_ALL)\n",
    "    writer.writerow(mybag_img_url_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHARLES & KEITH web crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "모든 백 사진 url 다운로드를 시작합니다\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "1번째 페이지 이미지를 다운로드 중입니다!\n",
      "2번째 페이지 이미지를 다운로드 중입니다!\n",
      "3번째 페이지 이미지를 다운로드 중입니다!\n",
      "4번째 페이지 이미지를 다운로드 중입니다!\n",
      "5번째 페이지 이미지를 다운로드 중입니다!\n",
      "6번째 페이지 이미지를 다운로드 중입니다!\n",
      "7번째 페이지 이미지를 다운로드 중입니다!\n",
      "8번째 페이지 이미지를 다운로드 중입니다!\n"
     ]
    }
   ],
   "source": [
    "## All bag\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"모든 백 사진 url 다운로드를 시작합니다\")\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "current_page = 1\n",
    "\n",
    "img_url_list = []\n",
    "\n",
    "while current_page <= 8:\n",
    "    print(str(current_page) + \"번째 페이지 이미지를 다운로드 중입니다!\")\n",
    "    url = 'https://www.charleskeith.com/sg/bags' + '?p=' + str(current_page)\n",
    "    web = urlopen(url)\n",
    "    source = BeautifulSoup(web, 'html.parser')\n",
    "    for a in source.find_all('div', {\"class\" : \"pcp-owl-carousel owl-carousel\" }):\n",
    "        for url in a.find_all(\"img\"):\n",
    "            if url[\"src\"].startswith('https://d3qsystxi9mvxa.cloudfront.net/media/'):\n",
    "                img_url_list.append(url[\"src\"])\n",
    "                \n",
    "    current_page = current_page + 1            \n",
    "    time.sleep(5)\n",
    "\n",
    "\n",
    "ck_img_url_list = list(set(img_url_list))\n",
    "\n",
    "ck_img_url_list\n",
    "\n",
    "ck_img_url_list = list(set(ck_img_url_list))\n",
    "\n",
    "len(ck_img_url_list)\n",
    "\n",
    "## write to csv file\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('./data/bag_image_url_csv/ck_all_bag.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f, quoting=csv.QUOTE_ALL)\n",
    "    writer.writerow(ck_img_url_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# musinsa web crawling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "모든 백 사진 url 다운로드를 시작합니다\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "1번째 페이지 이미지를 다운로드 중입니다!\n",
      "2번째 페이지 이미지를 다운로드 중입니다!\n",
      "3번째 페이지 이미지를 다운로드 중입니다!\n",
      "4번째 페이지 이미지를 다운로드 중입니다!\n",
      "5번째 페이지 이미지를 다운로드 중입니다!\n",
      "6번째 페이지 이미지를 다운로드 중입니다!\n",
      "7번째 페이지 이미지를 다운로드 중입니다!\n",
      "8번째 페이지 이미지를 다운로드 중입니다!\n",
      "9번째 페이지 이미지를 다운로드 중입니다!\n",
      "10번째 페이지 이미지를 다운로드 중입니다!\n"
     ]
    }
   ],
   "source": [
    "## All bag\n",
    "\n",
    "from bs4 import BeautifulSoup \n",
    "from urllib.request import urlopen \n",
    "import time\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"모든 백 사진 url 다운로드를 시작합니다\")\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "current_page = 1\n",
    "\n",
    "img_url_list = []\n",
    "\n",
    "while current_page <= 10:\n",
    "    print(str(current_page) + \"번째 페이지 이미지를 다운로드 중입니다!\")\n",
    "    url = 'https://store.musinsa.com/app/items/lists/004003/?category=&d_cat_cd=004003&u_cat_cd=&brand=&sort=pop&display_cnt=80&page='+ str(current_page) + '&page_kind=category&list_kind=big&free_dlv=&ex_soldout=&sale_goods=&exclusive_yn=&price=&color=&a_cat_cd=&sex=&size=&tag=&popup=&brand_favorite_yn=&goods_favorite_yn=&blf_yn=&price1=&price2='\n",
    "    web = urlopen(url)\n",
    "    source = BeautifulSoup(web, 'html.parser')\n",
    "    for a in source.find_all('div', {\"class\" : \"list_img\" }):\n",
    "        for url in a.find_all(\"img\"):\n",
    "            if url[\"src\"].startswith('//image.msscdn.net/images/'):\n",
    "                img_url_list.append(url[\"src\"])\n",
    "                \n",
    "    current_page = current_page + 1            \n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All bag\n",
    "\n",
    "current_page = 11\n",
    "\n",
    "while current_page <= 25:\n",
    "    print(str(current_page) + \"번째 페이지 이미지를 다운로드 중입니다!\")\n",
    "    url = 'https://store.musinsa.com/app/items/lists/004003/?category=&d_cat_cd=004003&u_cat_cd=&brand=&sort=pop&display_cnt=80&page=' + str(current_page) +'&page_kind=category&list_kind=small&free_dlv=&ex_soldout=&sale_goods=&exclusive_yn=&price=&color=&a_cat_cd=&sex=&size=&tag=&popup=&brand_favorite_yn=&goods_favorite_yn=&blf_yn=&price1=&price2=&brand_favorite=&goods_favorite=&chk_exclusive=&chk_sale=&chk_soldout='\n",
    "    web = urlopen(url)\n",
    "    source = BeautifulSoup(web, 'html.parser')\n",
    "    for a in source.find_all('div', {\"class\" : \"list_img\" }):\n",
    "        for url in a.find_all(\"img\"):\n",
    "            if url[\"src\"].startswith('//image.msscdn.net/images/'):\n",
    "                img_url_list.append(url[\"src\"])\n",
    "                \n",
    "    current_page = current_page + 1            \n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All bag\n",
    "\n",
    "current_page = 26\n",
    "\n",
    "while current_page <= 40:\n",
    "    print(str(current_page) + \"번째 페이지 이미지를 다운로드 중입니다!\")\n",
    "    url = 'https://store.musinsa.com/app/items/lists/004003/?category=&d_cat_cd=004003&u_cat_cd=&brand=&sort=pop&display_cnt=80&page=' + str(current_page) +'&page_kind=category&list_kind=small&free_dlv=&ex_soldout=&sale_goods=&exclusive_yn=&price=&color=&a_cat_cd=&sex=&size=&tag=&popup=&brand_favorite_yn=&goods_favorite_yn=&blf_yn=&price1=&price2=&brand_favorite=&goods_favorite=&chk_exclusive=&chk_sale=&chk_soldout='\n",
    "    web = urlopen(url)\n",
    "    source = BeautifulSoup(web, 'html.parser')\n",
    "    for a in source.find_all('div', {\"class\" : \"list_img\" }):\n",
    "        for url in a.find_all(\"img\"):\n",
    "            if url[\"src\"].startswith('//image.msscdn.net/images/'):\n",
    "                img_url_list.append(url[\"src\"])\n",
    "                \n",
    "    current_page = current_page + 1            \n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All bag\n",
    "\n",
    "current_page = 41\n",
    "\n",
    "while current_page <= 55:\n",
    "    print(str(current_page) + \"번째 페이지 이미지를 다운로드 중입니다!\")\n",
    "    url = 'https://store.musinsa.com/app/items/lists/004003/?category=&d_cat_cd=004003&u_cat_cd=&brand=&sort=pop&display_cnt=80&page=' + str(current_page) +'&page_kind=category&list_kind=small&free_dlv=&ex_soldout=&sale_goods=&exclusive_yn=&price=&color=&a_cat_cd=&sex=&size=&tag=&popup=&brand_favorite_yn=&goods_favorite_yn=&blf_yn=&price1=&price2=&brand_favorite=&goods_favorite=&chk_exclusive=&chk_sale=&chk_soldout='\n",
    "    web = urlopen(url)\n",
    "    source = BeautifulSoup(web, 'html.parser')\n",
    "    for a in source.find_all('div', {\"class\" : \"list_img\" }):\n",
    "        for url in a.find_all(\"img\"):\n",
    "            if url[\"src\"].startswith('//image.msscdn.net/images/'):\n",
    "                img_url_list.append(url[\"src\"])\n",
    "                \n",
    "    current_page = current_page + 1            \n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All bag\n",
    "\n",
    "current_page = 56\n",
    "\n",
    "while current_page <= 85:\n",
    "    print(str(current_page) + \"번째 페이지 이미지를 다운로드 중입니다!\")\n",
    "    url = 'https://store.musinsa.com/app/items/lists/004003/?category=&d_cat_cd=004003&u_cat_cd=&brand=&sort=pop&display_cnt=80&page=' + str(current_page) +'&page_kind=category&list_kind=small&free_dlv=&ex_soldout=&sale_goods=&exclusive_yn=&price=&color=&a_cat_cd=&sex=&size=&tag=&popup=&brand_favorite_yn=&goods_favorite_yn=&blf_yn=&price1=&price2=&brand_favorite=&goods_favorite=&chk_exclusive=&chk_sale=&chk_soldout='\n",
    "    web = urlopen(url)\n",
    "    source = BeautifulSoup(web, 'html.parser')\n",
    "    for a in source.find_all('div', {\"class\" : \"list_img\" }):\n",
    "        for url in a.find_all(\"img\"):\n",
    "            if url[\"src\"].startswith('//image.msscdn.net/images/'):\n",
    "                img_url_list.append(url[\"src\"])\n",
    "                \n",
    "    current_page = current_page + 1            \n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All bag\n",
    "\n",
    "current_page = 86\n",
    "\n",
    "while current_page <= 100:\n",
    "    print(str(current_page) + \"번째 페이지 이미지를 다운로드 중입니다!\")\n",
    "    url = 'https://store.musinsa.com/app/items/lists/004003/?category=&d_cat_cd=004003&u_cat_cd=&brand=&sort=pop&display_cnt=80&page=' + str(current_page) +'&page_kind=category&list_kind=small&free_dlv=&ex_soldout=&sale_goods=&exclusive_yn=&price=&color=&a_cat_cd=&sex=&size=&tag=&popup=&brand_favorite_yn=&goods_favorite_yn=&blf_yn=&price1=&price2=&brand_favorite=&goods_favorite=&chk_exclusive=&chk_sale=&chk_soldout='\n",
    "    web = urlopen(url)\n",
    "    source = BeautifulSoup(web, 'html.parser')\n",
    "    for a in source.find_all('div', {\"class\" : \"list_img\" }):\n",
    "        for url in a.find_all(\"img\"):\n",
    "            if url[\"src\"].startswith('//image.msscdn.net/images/'):\n",
    "                img_url_list.append(url[\"src\"])\n",
    "                \n",
    "    current_page = current_page + 1            \n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "musinsa_list = list(set(img_url_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "musinsa_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(musinsa_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write to csv file\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('./data/bag_image_url_csv/musinsa_all_bag.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f, quoting=csv.QUOTE_ALL)\n",
    "    writer.writerow(musinsa_img_url_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
